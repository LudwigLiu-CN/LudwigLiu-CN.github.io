<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Notes of ENAS</title>
    <url>/2019/11/02/ENAS/</url>
    <content><![CDATA[<p>ENAS is introduced by my mentor of my research on the classification of malignant thyroid nodules. This could be a good way to set the basic architecture of our net work. So I read this paper.</p>
<a id="more"></a>

<h1 id="Efficient-Neural-Architecture-Search-via-Parameter-Sharing"><a href="#Efficient-Neural-Architecture-Search-via-Parameter-Sharing" class="headerlink" title="Efficient Neural Architecture Search via Parameter Sharing"></a>Efficient Neural Architecture Search via Parameter Sharing</h1><p> <a href="https://arxiv.org/abs/1802.03268" target="_blank" rel="noopener">https://arxiv.org/abs/1802.03268</a> </p>
<ul>
<li><p><strong>Abstract:</strong>  We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design.  </p>
</li>
<li><p><strong>Designing Recurrent Cells:</strong></p>
<p>Our search space includes an exponential number of configurations. Specifically, if the recurrent cell has N nodes and we allow 4 activation functions (namely tanh, ReLU, identity, and sigmoid), then the search space has 4 N × N! configurations. </p>
<p><img src="/2019/11/02/ENAS/1.PNG" alt="1"></p>
<ol>
<li>At node 1: The controller first samples an activation function. In our example, the controller chooses the tanh activation function, which means that node 1 of the recurrent cell should compute h<sub>1</sub> = tanh (x<sub>t</sub> · W<sup>(x)</sup> + h<sub>t−1</sub> · W<sub>1</sub><sup>(h)</sup>  ). </li>
<li>At node 2: The controller then samples a previous index and an activation function. In our example, it chooses the previous index 1 and the activation function ReLU. Thus, node 2 of the cell computes h<sub>2</sub> = ReLU(h<sub>1</sub> · W<sub>2,1</sub><sup>(h)</sup> ). </li>
<li>At node 3: The controller again samples a previous index and an activation function. In our example, it chooses the previous index 2 and the activation function ReLU. Therefore, h<sub>3</sub> = ReLU(h<sub>2</sub> · W<sub>3,2</sub><sup>(h)</sup>). </li>
<li>At node 4: The controller again samples a previous index and an activation function. In our example, it chooses the previous index 1 and the activation function tanh, leading to h4 = tanh (h<sub>1</sub> · W<sub>4,1</sub><sup>(h)</sup>). </li>
<li>For the output, we simply average all the loose ends, i.e. the nodes that are not selected as inputs to any other nodes. In our example, since the indices 3 and 4 were never sampled to be the input for any node, the recurrent cell uses their average (h<sub>3</sub> + h<sub>4</sub>)/2 as its output. In other words, h<sub>t</sub> = (h<sub>3</sub> + h<sub>4</sub>)/2. </li>
</ol>
<p><strong>Controller:</strong></p>
<p>ENAS’s controller is an RNN that decides: 1) which edges are activated and 2) which computations are performed at each node in the DAG. Our controller network is an LSTM with 100 hidden units.</p>
<p><strong>Training ENAS and Deriving Architecture:</strong> </p>
<p>The training procedure of ENAS consists of two interleaving phases. The first phase trains ω, the shared parameters of the child models, on a whole pass through the training data set. The second phase trains θ, the parameters of the controller LSTM, for a fixed number of steps, typically set to 2000 in our experiments.</p>
<p><strong>Designing Convolutional Networks:</strong></p>
<p>The controller RNN also samples two sets of decisions at each decision block: 1) what previous nodes to connect to and 2) what computation operation to use.</p>
<p><img src="/2019/11/02/ENAS/2.PNG" alt="2"></p>
<p><strong>Designing Convolutional Cells:</strong> </p>
<p>Rather than designing the entire convolutional network, one can design smaller modules and then connect them together to form a network. </p>
<p><img src="/2019/11/02/ENAS/3.PNG" alt="3"></p>
<ol>
<li>Nodes 1, 2 are input nodes, so no decisions are needed for them. Let h1, h2 be the outputs of these nodes. </li>
<li>At node 3: the controller samples two previous nodes and two operations. In Figure 5 Top Left, it samples node 2, node 2, separable conv 5x5, and identity. This means that h3 = sep conv 5x5(h2) + id(h2).</li>
<li>At node 4: the controller samples node 3, node 1, avg pool 3x3, and sep conv 3x3. This means that h4 = avg pool 3x3(h3) + sep conv 3x3(h1).</li>
<li>Since all nodes but h4 were used as inputs to at least another node, the only loose end, h4, is treated as the cell’s output. If there are multiple loose ends, they will be concatenated along the depth dimension to form the cell’s output.  </li>
</ol>
</li>
<li><p><strong>P.S.</strong></p>
<p>Actually, after reading this paper I only have the slightest understanding of this Net Work, and as for the details like what’s really going on when training, and how do those parameters in one unit change  and cast influence on another unit, they still seem quite unclear to me.</p>
<p> <a href="https://github.com/shibuiwilliam/ENAS-Keras" target="_blank" rel="noopener">https://github.com/shibuiwilliam/ENAS-Keras</a> This is Keras implementation of ENAS. I ran the file  <a href="https://github.com/shibuiwilliam/ENAS-Keras/blob/master/ENAS_Keras_MNIST.ipynb" target="_blank" rel="noopener">ENAS_Keras_MNIST.ipynb</a> on my workstation with 2 GPUs of 1080ti, and found that it requires days to finish running. Then, I ran it on my data set of thyroid nodules, it still finished only 1/3 of the work load in 24h. Apparently, it’s unrealistic to use this method to build my network for its training price is too high to afford. But still this method could come handy in the future.</p>
<p>Besides, while collecting information about this method, I find something called auto-Keras, which is based on ENAS. It can figure out a suitable network architecture for the data you input, and then you can do some improving work based on it. It’s an open source project. I think it’s an excellent way to start a new network. I will do some digging about it in the future days.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Deep Learning</category>
        <category>Essay Notes</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>CNNs of Thyroid Nodule Classification</title>
    <url>/2019/10/30/ThyroidNoduleClassificationNote/</url>
    <content><![CDATA[<p>I’m currently doing some research on classification of thyroid nodules by CNN. This is a note of some essays I found in this area.</p>
<a id="more"></a>

<h1 id="Classification-of-thyroid-nodules-in-ultrasound-images-using-deep-model-based-transfer-learning-and-hybrid-features"><a href="#Classification-of-thyroid-nodules-in-ultrasound-images-using-deep-model-based-transfer-learning-and-hybrid-features" class="headerlink" title="Classification of thyroid nodules in ultrasound images using deep model based transfer learning and hybrid features"></a><strong>Classification of thyroid nodules in ultrasound images using deep model based transfer learning and hybrid features</strong></h1><p><a href="https://ieeexplore.ieee.org/abstract/document/7952290" target="_blank" rel="noopener">https://ieeexplore.ieee.org/abstract/document/7952290</a></p>
<ul>
<li><p><strong>Abstract:</strong></p>
<p>Besides the general feature map extracted by the CNN, this work combines it with other hand-crafted features of the images. They integrated HOG, SIFT and LBP features with the high-level features extracted from CNNs and jointed them to form a one-dimensional vector.</p>
<p><img src="/2019/10/30/ThyroidNoduleClassificationNote/1.gif" alt="1"></p>
</li>
<li><p><strong>Feature selection strategy:</strong></p>
<p>The feature map extracted from the VGG-F model has 4096 dimensions. With 144 dimensions’ HOG features, 26 dimensions’ LBP features and 512 dimensions’ VLAD features, the total count of feature dimensions we have is 4778. In order to reducing the redundancies and irrelevancies among feature vector, feature selection is required. The feature selection standard is based on sorting the differences of benign samples and malignant samples:<br>$$<br>diff_k = \vert\frac{1}{N_{MB}}\sum_{i=1}^{N_{MB}}{v_{ik}} - \frac{1}{N_{MM}}\sum_{i=1}^{N_{MM}}{v_{ik}}\vert \quad (k = 1, 2,…N)<br>$$<br>Where, <em>N<sub>MB</sub></em> and <em>N<sub>MM</sub></em> are the number of benign and malignant nodules in the training set, <em>v<sub>ik</sub></em> is the <em>k</em>th dimensional feature of the <em>i</em>th image. The top 1000 features with the largest differences will be chosen as our final features for the thyroid nodule classification. </p>
<p><strong>Positive-Sample-First Majority Voting Strategy:</strong></p>
<p>Suppose T types of features can be extracted from the thyroid ultrasound images. For a feature extraction method <em>k</em>, a classifier <em>h<sub>k</sub></em> can be trained on the dataset. The value predicted by the classifier for sample x is <em>h<sub>k</sub></em>(x). The final predicted classification result for sample x is expressed as follows, <em>h(x)=mode(h<sub>1</sub>(x),…,h<sub>T</sub>(x))</em>, where the <em>mode</em> is striving for the modal operation. If the votes of benign and malignance are the same on the condition that T is an even number, the sample is considered as malignancy.  </p>
</li>
</ul>
<h1 id="A-pre-trained-convolutional-neural-network-based-method-for-thyroid-nodule-diagnosis"><a href="#A-pre-trained-convolutional-neural-network-based-method-for-thyroid-nodule-diagnosis" class="headerlink" title="A pre-trained convolutional neural network based method for thyroid nodule diagnosis"></a>A pre-trained convolutional neural network based method for thyroid nodule diagnosis</h1><p> <a href="https://www.sciencedirect.com/science/article/pii/S0041624X16301913" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/pii/S0041624X16301913</a> </p>
<ul>
<li><p><strong>Abstract:</strong> </p>
<p>In this study, we propose a hybrid method for thyroid nodule diagnosis, which is a fusion of two pre-trained convolutional neural networks (CNNs) with different convolutional layers and fully-connected layers.  </p>
<p><img src="/2019/10/30/ThyroidNoduleClassificationNote/4.jpg" alt="4"></p>
</li>
<li><p><strong>Data:</strong>  </p>
<p>Each thyroid nodule has several longitudinal cutting maps or crosscutting maps. In total, 15,000 thyroid nodule images are obtained from different sonographic systems (Philips, GE-Healthcare, Esaote, Toshiba, Siemens, mindray and Hitachi) before surgery or FNA. The boundary of thyroid nodule in each image is manually delineated by physicians. So we can get 15,000 masks. These thyroid nodule images and their corresponding masks are in the same size and are both used for training our CNNs simultaneously. </p>
<p><img src="/2019/10/30/ThyroidNoduleClassificationNote/2.jpg" alt="2"></p>
<p><strong>Combination of two different CNNs:</strong></p>
<p> A special CNN based method is developed to classify thyroid nodules, which is a fusion of two different CNN architectures. Moreover, these two CNNs use a pre-training strategy for initialization to avoid local optimum and employ a multi-view strategy to improve the performance. </p>
<p>To the best of our knowledge, different CNN architectures can learn different features, shallow network can be suitable for learning low-level features and deep network can take full advantage of learning high-level features. </p>
<p>Our CNN architectures are pre-trained with a set of 1.3 million natural images from the ImageNet database. </p>
<p>The image patches of size 225 * 225 cropped sampled randomly from thyroid nodule images are the inputs of our CNN based models, whose centers are in their corresponding masks.  </p>
<p><strong>Split Dropout:</strong></p>
<p><img src="/2019/10/30/ThyroidNoduleClassificationNote/3.jpg" alt="3"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Deep Learning</category>
        <category>Essay Notes</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>CNN</tag>
        <tag>Medical Image</tag>
      </tags>
  </entry>
  <entry>
    <title>My Hello World</title>
    <url>/2019/10/29/My-Hello-World/</url>
    <content><![CDATA[<p>My first  blog on this website!</p>
<p><img src="/2019/10/29/My-Hello-World/TheDarkSideOfTheMoon.jpg" alt="TheDarkSideOfTheMoon"></p>
<a id="more"></a>

<p>My first  blog on this website! As a matter of fact, I’ve been thinking about this for a long time. But not until a friend of mine introduce Hexo to me did I realize how easy it actually is to start my own blog. </p>
<p>So now, I’m here ready to record something of my life, meaningful or not. Mainly my blogs will be about coding or computer skills, but once in a while I’d like to record some other fun stuffs here, you know, something like ‘The Dark Side of the Moon’ by Pink Floyd I’m listening to now, and rock music, basketball, video games and so on.</p>
<p>And also, thanks for visiting my blog!</p>
]]></content>
      <categories>
        <category>personal journal or something</category>
      </categories>
      <tags>
        <tag>hello world</tag>
        <tag>daily</tag>
      </tags>
  </entry>
</search>
